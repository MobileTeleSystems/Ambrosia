{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565e7f2f",
   "metadata": {},
   "source": [
    "# Overview of *Ambrosia* ``Tester`` class Spark data support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e50f8",
   "metadata": {},
   "source": [
    "This example gives brief overview of the Splitter class functionality on Spark DataFrames. Synthetic data on the time spent on viewing content by MTS KION users is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5071adb4",
   "metadata": {},
   "source": [
    "The functionality of the ``Tester`` class on Spark data currently is limited and **only two-sampled independed t-test cant be used**. \\\n",
    "See the main ``Tester`` tutorial on pandas data to learn the full functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0cbd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "\n",
    "from ambrosia.tester import Tester"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27f46b",
   "metadata": {},
   "source": [
    "Build local spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22faaae9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 17:40:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/21 17:40:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "os.environ['SPARK_LOCAL_IP'] = '127.0.0.1'\n",
    "spark = pyspark.sql.SparkSession.builder.master(\"local[1]\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26defd2",
   "metadata": {},
   "source": [
    "Create Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05d2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "kion_watch_results_agg = pd.read_csv('../tests/test_data/watch_result_agg.csv')\n",
    "sdf = spark.createDataFrame(kion_watch_results_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36e1c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- watched: double (nullable = true)\n",
      " |-- group: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78fb328",
   "metadata": {},
   "source": [
    "## Using t-test for Spark data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22891d",
   "metadata": {},
   "source": [
    "The interface for using the ``Tester`` class is exactly the same as in the case of pandas data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003569e2",
   "metadata": {},
   "source": [
    "Let's create an instance of the class and pass the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ddb493e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_tester = Tester(dataframe=sdf,\n",
    "                      column_groups='group',\n",
    "                      first_type_errors=0.05,\n",
    "                      metrics='watched')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c5038",
   "metadata": {},
   "source": [
    "Now take a look at the absolute results of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b87df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_type_error</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>effect</th>\n",
       "      <th>confidence_interval</th>\n",
       "      <th>metric name</th>\n",
       "      <th>group A label</th>\n",
       "      <th>group B label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>55.314679</td>\n",
       "      <td>(26.54, 84.0893)</td>\n",
       "      <td>watched</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_type_error    pvalue     effect confidence_interval metric name  \\\n",
       "0              0.05  0.000022  55.314679    (26.54, 84.0893)     watched   \n",
       "\n",
       "  group A label group B label  \n",
       "0             A             B  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_tester.run(effect_type='absolute', method='theory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fbe1af",
   "metadata": {},
   "source": [
    "And at the relative effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a8afc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_type_error</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>effect</th>\n",
       "      <th>confidence_interval</th>\n",
       "      <th>metric name</th>\n",
       "      <th>group A label</th>\n",
       "      <th>group B label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.079901</td>\n",
       "      <td>(0.0419, 0.1183)</td>\n",
       "      <td>watched</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_type_error   pvalue    effect confidence_interval metric name  \\\n",
       "0              0.05  0.00004  0.079901    (0.0419, 0.1183)     watched   \n",
       "\n",
       "  group A label group B label  \n",
       "0             A             B  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_tester.run(effect_type='relative', method='theory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3decada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
